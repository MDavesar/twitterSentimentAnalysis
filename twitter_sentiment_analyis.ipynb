{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS3NXBn__PE2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/0000000000002747_training_twitter_x_y_train.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_l8daQfO2rBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df = pd.concat([df,data['text']],axis=1)\n",
        "df = pd.concat([df,data['airline_sentiment']],axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LCxpX4HvATxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "metadata": {
        "id": "cAm2l4QUElu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "stop = stopwords.words('english')\n",
        "punc = list(string.punctuation)\n",
        "stop = stop+punc\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "dk0ckr0QAwKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "def get_simple_pos(tag): #creating simple tags to pass into the lemmatizer\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n"
      ],
      "metadata": {
        "id": "onKa6rmbDG_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fNfCs_8OE9sI",
        "outputId": "88b7a0c0-cac1-4176-c042-e8b3c0b89676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@SouthwestAir I am scheduled for the morning, 2 days after the fact, yes..not sure why my evening flight was the only one Cancelled Flightled'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(string):\n",
        "    words = word_tokenize(string)\n",
        "    #print(words)\n",
        "    clean_words = []\n",
        "    for word in words:\n",
        "      if word.lower() not in stop:\n",
        "        pos = pos_tag([word])\n",
        "       # print(pos)\n",
        "        new = lemmatizer.lemmatize(word,get_simple_pos(pos[0][1]))\n",
        "        clean_words.append(new)\n",
        "    return clean_words"
      ],
      "metadata": {
        "id": "T3sRltmkBWVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text= []\n",
        "for tweet in df['text']:\n",
        "  clean_text.append(clean_tweet(tweet))\n"
      ],
      "metadata": {
        "id": "D_9Y3e0jGdjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_docs = []\n",
        "for i in clean_text:\n",
        "  text_docs.append(\" \".join(i))\n",
        "len(text_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5nomPfF7tl_",
        "outputId": "6d4ff72a-4116-4d25-8e62-321337aedffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10980"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame()\n",
        "Y = pd.DataFrame()"
      ],
      "metadata": {
        "id": "3UJk83R931WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['text_docs'] = text_docs\n",
        "Y = pd.concat([Y,df['airline_sentiment']],axis=1)\n",
        "Y.head"
      ],
      "metadata": {
        "id": "W2zEm9JE4NrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,Y)\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "nHU56oIf42If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features =1000,max_df=.8)"
      ],
      "metadata": {
        "id": "PLjoASXr5QiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = cv.fit_transform(x_train['text_docs'])"
      ],
      "metadata": {
        "id": "TbsZNkxQ5n0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = cv.transform(x_test['text_docs'])"
      ],
      "metadata": {
        "id": "gSsuUvcg9TsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression()\n",
        "lr.fit(a,y_train)\n",
        "lr.score(b,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKPWQQ2V_upW",
        "outputId": "fba4f37b-eed9-47e1-eed1-3b9f5a9446fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7839708561020037"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(a,y_train)\n",
        "rf.score(b,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUDfRNuvL940",
        "outputId": "03930ecf-d0d0-4893-f719-a1696f88f888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-577cb45b8ec3>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf.fit(a,y_train)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7526411657559199"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "sv = svm.SVC()\n",
        "sv.fit(a,y_train)\n",
        "sv.score(b,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIG8qiAXMVeC",
        "outputId": "dfdb0bbf-4ca7-47d2-af1e-7e13fc03c708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7799635701275045"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "481FDNIdGe7c"
      }
    }
  ]
}